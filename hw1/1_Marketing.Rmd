---
title: "Probelem 1 - Data Mining Marketing"
author: "Henry Neeb, Christopher Kurrus, Tyler Chase"
date: "April 16, 2016"
output: pdf_document
---

## Libraries

```{r}
library(ggplot2)
library(dplyr)
library(readr)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
```

## File Parameters

```{r}
# Session -> set working directory -> Source file location

# Path for data
data_path <- "data/"
file <- "Income_Data.txt"
ext <- paste(data_path, file, sep = "")
```

## Read in Data

```{r}
# Name of the variables imported
var_names = c("income",
              "sex",
              "marital_status",
              "age",
              "education",
              "occupation",
              "bay_duration",
              "dual_income",
              "household_total",
              "household_minors",
              "householder_status",
              "home_type",
              "ethnicity",
              "language")

# Type of the variable being imported
var_type <- cols(col_factor(sprintf("%i", 1:9), ordered =  TRUE), # income
                 col_factor(sprintf("%i", 1:2), ordered = FALSE), # sex
                 col_factor(sprintf("%i", 1:5), ordered = FALSE), # marital stat
                 col_factor(sprintf("%i", 1:7), ordered =  TRUE), # age
                 col_factor(sprintf("%i", 1:6), ordered =  TRUE), # education
                 col_factor(sprintf("%i", 1:9), ordered = FALSE), # occupation
                 col_factor(sprintf("%i", 1:5), ordered =  TRUE), # bay duration
                 col_factor(sprintf("%i", 1:3), ordered = FALSE), # dual income
                 col_factor(sprintf("%i", 1:9), ordered =  TRUE), # house count
                 col_factor(sprintf("%i", 0:9), ordered =  TRUE), # minor count
                 col_factor(sprintf("%i", 1:3), ordered = FALSE), # rent/own
                 col_factor(sprintf("%i", 1:5), ordered = FALSE), # house type
                 col_factor(sprintf("%i", 1:8), ordered = FALSE), # ethnicity
                 col_factor(sprintf("%i", 1:3), ordered = FALSE)) # language

var_type <- cols(col_factor(sprintf("%i", 1:9), ordered = FALSE), # income
                 col_factor(sprintf("%i", 1:2), ordered = FALSE), # sex
                 col_factor(sprintf("%i", 1:5), ordered = FALSE), # marital stat
                 col_factor(sprintf("%i", 1:7), ordered = FALSE), # age
                 col_factor(sprintf("%i", 1:6), ordered = FALSE), # education
                 col_factor(sprintf("%i", 1:9), ordered = FALSE), # occupation
                 col_factor(sprintf("%i", 1:5), ordered = FALSE), # bay duration
                 col_factor(sprintf("%i", 1:3), ordered = FALSE), # dual income
                 col_factor(sprintf("%i", 1:9), ordered = FALSE), # house count
                 col_factor(sprintf("%i", 0:9), ordered = FALSE), # minor count
                 col_factor(sprintf("%i", 1:3), ordered = FALSE), # rent/own
                 col_factor(sprintf("%i", 1:5), ordered = FALSE), # house type
                 col_factor(sprintf("%i", 1:8), ordered = FALSE), # ethnicity
                 col_factor(sprintf("%i", 1:3), ordered = FALSE)) # language

df <- read_csv(file = ext, 
               col_names = var_names, 
               col_types = var_type)
```

The data does not have any column headers, so we have to manually assign the 
column names. Our variables are also all categorical variables, some with an 
order relationship and some with out. We also have to import these values as 
factors, specifiying if they have an order relationship or not. The following 
variables have an order relationship:

* Income
* Age
* Education
* Amount of time living in the bay area
* Household count
* Minors in household count

The remaining variables do not have an order relationship:

* Sex
* Marital status
* Occupation
* Dual income status
* Whether you rent or own a house
* Type of house you live in
* Ethnicity
* Languages

## Fit a Maximal Tree Model for Pruning

We will first fit a tree with a low complexity paramter so that we can observe 
it's behavior and decide on an optimal parameter based on cross validation 
error. We will use the following control parameters:

* 10-fold cross validation
* 100 minsplit
* Use default surrogate parameters, except split by majority if split data and 
all surrogate information is missing.
* Use a low complexity parameter of 0.00001

```{r}
# Modify tree control parameters. Specify 10-fold cross validation, low cost, 
# minimum split needs at least 100 observations, and specify use correlation 
# surrogate if possible, else use majority
control_parms <- rpart.control(xval = 10L, 
                               minsplit = 100, 
                               usesurrogate = 2,
                               cp = .00001)

# Make a fit, specify classification model
fit <- rpart(formula = income ~ ., 
             data = df, 
             method = "class",
             control = control_parms)
```

Let us now look at cross-validation error versus our complexity parameter, as 
well as a summary of our model and cross-validation error.

```{r}
printcp(fit)
plotcp(fit)
```

The dashed line on plotcp marks the minimum cross validation error plus one 
standard error. We will use this rule for selecting a model - the model with 
the largest complexity parameter that produces a cross-validation error just 
below the sum of the two aforementioned values.

```{r}
# Find the index where cross validation is minimized to implement 1-SE rule
xerror_list <- fit$cptable[,"xerror"]
min_idx <- as.integer(which.min(xerror_list))
se_cutoff <- as.numeric(fit$cptable[,"xstd"][min_idx]) +
             as.numeric(xerror_list[min_idx])

# Find CP where cross-val error just dips below SE + min cross-val cutoff
opt_cp <- 1.0
for (i in seq_len(length(xerror_list))){
  if (xerror_list[i] < se_cutoff){
    opt_cp <- as.numeric(fit$cptable[,"CP"][i])
    break
  }
}
```

We will now prune the true according to this 1-Standard Error Rule complexity 
parameter and replot and print the complexity parameter.

```{r}
pruned_fit <- prune(tree = fit, cp = opt_cp)

plotcp(pruned_fit)
printcp(pruned_fit)
```

This will be our optimal tree. Lets look at a nice plot.

```{r}
fancyRpartPlot(model = pruned_fit, 
               main = "Pruned Decision Tree", 
               sub = "")
```




prune_fit <- prune(tree = fit, cp = 0.004)

print(prune_fit)

plotcp(fit)
print(fit)

plot(prune_fit, uniform = TRUE)
text(prune_fit, use.n = TRUE)

# Save file of tree image
post(tree = prune_fit, filename = "Income.ps", horizontal = FALSE)

# Alternate tree image
prp(x = fit)
```


